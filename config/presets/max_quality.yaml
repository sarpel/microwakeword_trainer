# ─────────────────────────────────────────────────────────────────
# MAX QUALITY PRESET - Maximum quality settings
# Use for: Production training with best accuracy
# ─────────────────────────────────────────────────────────────────

# ─────────────────────────────────────────────────────────────────
# HARDWARE PARAMETERS (IMMUTABLE)
# ─────────────────────────────────────────────────────────────────
hardware:
  sample_rate_hz: 16000
  mel_bins: 40
  window_size_ms: 30
  window_step_ms: 10
  clip_duration_ms: 1000

# ─────────────────────────────────────────────────────────────────
# PATHS
# ─────────────────────────────────────────────────────────────────
paths:
  positive_dir: "./dataset/positive"
  negative_dir: "./dataset/negative"
  hard_negative_dir: "./dataset/hard_negative"
  background_dir: "./dataset/background"
  rir_dir: "./dataset/rirs"
  processed_dir: "./dataset/processed"
  checkpoint_dir: "./models/checkpoints"
  export_dir: "./models/exported"

# ─────────────────────────────────────────────────────────────────
# TRAINING PARAMETERS
# ─────────────────────────────────────────────────────────────────
training:
  # Maximum steps for best quality
  training_steps: [50000, 20000]
  learning_rates: [0.001, 0.0001]
  batch_size: 128
  eval_step_interval: 500
  steps_per_epoch: 1000  # Approximate steps per epoch for mining calculations

  # Class weights - higher negative weight for fewer false accepts
  positive_class_weight: [1.0, 1.0]
  negative_class_weight: [25.0, 25.0]
  hard_negative_class_weight: [50.0, 50.0]

  # SpecAugment disabled (using full audio augmentation)
  time_mask_max_size: [0, 0]
  time_mask_count: [0, 0]
  freq_mask_max_size: [0, 0]
  freq_mask_count: [0, 0]

  # Checkpoint selection - stricter target for max quality
  minimization_metric: "ambient_false_positives_per_hour"
  target_minimization: 0.2
  maximization_metric: "average_viable_recall"
  # Hours of negative/background audio for FAH calculation
  ambient_duration_hours: 10.0

# ─────────────────────────────────────────────────────────────────
# MIXEDNET ARCHITECTURE
# ─────────────────────────────────────────────────────────────────
model:
  architecture: "mixednet"

  # okay_nabu architecture (official ESPHome MWW)
  first_conv_filters: 32
  first_conv_kernel_size: 5
  stride: 3
  pointwise_filters: "64,64,64,64"
  mixconv_kernel_sizes: "[5],[7,11],[9,15],[23]"
  repeat_in_block: "1,1,1,1"
  residual_connection: "0,0,0,0"

  # Common settings
  dropout_rate: 0.2
  l2_regularization: 0.0001

# ─────────────────────────────────────────────────────────────────
# AUGMENTATION (Full + extra for max quality)
# ─────────────────────────────────────────────────────────────────
augmentation:
  # Time-domain augmentations - higher probabilities
  SevenBandParametricEQ: 0.15
  TanhDistortion: 0.15
  PitchShift: 0.15
  BandStopFilter: 0.15
  AddColorNoise: 0.15
  AddBackgroundNoise: 0.8
  Gain: 1.0
  RIR: 0.6

  # Additional augmentations for max quality
  AddBackgroundNoiseFromFile: 0.3
  ApplyImpulseResponse: 0.4

  # Noise mixing parameters - wider range for max quality
  background_min_snr_db: -10
  background_max_snr_db: 15
  min_jitter_s: 0.19
  max_jitter_s: 0.21

  # Augmentation magnitude ranges - wider for max quality diversity
  eq_min_gain_db: -9.0
  eq_max_gain_db: 9.0
  distortion_min: 0.05
  distortion_max: 0.7
  pitch_shift_min_semitones: -3.0
  pitch_shift_max_semitones: 3.0
  band_stop_min_center_freq: 80.0
  band_stop_max_center_freq: 6000.0
  band_stop_min_bandwidth_fraction: 0.5
  band_stop_max_bandwidth_fraction: 1.99
  gain_min_db: -6.0
  gain_max_db: 6.0
  color_noise_min_snr_db: -10.0
  color_noise_max_snr_db: 15.0

  # Background sources - use your own dataset paths
  impulse_paths: ["./dataset/rirs"]
  background_paths: ["./dataset/background"]
  augmentation_duration_s: 3.2

# ─────────────────────────────────────────────────────────────────
# PERFORMANCE CONFIGURATION (Maximum resources)
# ─────────────────────────────────────────────────────────────────
performance:
  # GPU mandatory for max quality
  gpu_only: true
  mixed_precision: true

  # Maximum CPU resources
  num_workers: 16
  num_threads_per_worker: 2
  prefetch_factor: 8
  pin_memory: true
  max_memory_gb: 60

  # Maximum parallelism
  inter_op_parallelism: 16
  intra_op_parallelism: 16

  # Profiling enabled with detailed output
  enable_profiling: false
  profile_every_n_steps: 100
  profile_output_dir: "./profiles"

  # TensorBoard enabled with full metrics
  tensorboard_enabled: true
  tensorboard_log_dir: "./logs"

# ─────────────────────────────────────────────────────────────────
# SPEAKER CLUSTERING (Enabled with strict settings)
# ─────────────────────────────────────────────────────────────────
speaker_clustering:
  enabled: true
  method: "agglomerative"
  embedding_model: "speechbrain/ecapa-tdnn-voxceleb"
  similarity_threshold: 0.75
  leakage_audit_enabled: true

# ─────────────────────────────────────────────────────────────────
# HARD NEGATIVE MINING (Enabled with aggressive settings)
# ─────────────────────────────────────────────────────────────────
hard_negative_mining:
  enabled: true
  fp_threshold: 0.75
  max_samples: 10000
  mining_interval_epochs: 3

# ─────────────────────────────────────────────────────────────────
# EXPORT SETTINGS
# ─────────────────────────────────────────────────────────────────
export:
  wake_word: "Hey Katya"
  author: "Sarpel GURAY"
  website: "https://github.com/sarpel/microwakeword-training-platform"
  trained_languages: ["en"]

  quantize: true
  inference_input_type: "int8"
  inference_output_type: "uint8"

  # Wake word detection threshold (high-confidence production-safe threshold)
  # Validated optimal cutoff from model validation
  probability_cutoff: 0.97
  sliding_window_size: 5
  tensor_arena_size: 30000
  minimum_esphome_version: "2024.7.0"

# ─────────────────────────────────────────────────────────────────
# PREPROCESSING (strict settings for max quality datasets)
# ─────────────────────────────────────────────────────────────────
preprocessing:
  min_duration_ms: 300.0
  max_duration_ms: 2000.0
  discarded_dir: "./discarded"
  vad_aggressiveness: 3       # most aggressive VAD for max quality
  vad_pad_ms: 150             # tighter padding for cleaner clips
  vad_frame_ms: 30
  split_max_chunk_ms: 2000.0
  split_min_chunk_ms: 500.0
  split_target_chunk_ms: 2000.0

# ─────────────────────────────────────────────────────────────────
# QUALITY SCORING THRESHOLDS (strict - only high-quality audio)
# ─────────────────────────────────────────────────────────────────
quality:
  clip_threshold: 0.001
  max_clip_ratio: 0.005       # strict: < 0.5% clipping
  discard_bottom_pct: 10.0    # discard lowest 10% for max quality
  min_wqi: 0.3                # require minimum quality index
  discarded_quality_dir: "./discarded/quality"
  min_snr_db: 0.0             # require positive SNR
  vad_speech_threshold: 0.5   # require ≥50% speech frames
  dnsmos_min_ovrl: 2.0        # require decent DNSMOS OVRL
  dnsmos_min_sig: 2.5         # require good DNSMOS signal
  dnsmos_cache_dir: "~/.cache/dnsmos"
