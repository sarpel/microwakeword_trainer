# ─────────────────────────────────────────────────────────────────
# MAX QUALITY PRESET - Maximum quality settings
# Use for: Production training with best accuracy
# ─────────────────────────────────────────────────────────────────

# ─────────────────────────────────────────────────────────────────
# HARDWARE PARAMETERS (IMMUTABLE)
# ─────────────────────────────────────────────────────────────────
hardware:
  sample_rate_hz: 16000
  mel_bins: 40
  window_size_ms: 30
  window_step_ms: 10
  clip_duration_ms: 1000

# ─────────────────────────────────────────────────────────────────
# PATHS
# ─────────────────────────────────────────────────────────────────
paths:
  positive_dir: "./dataset/positive"
  negative_dir: "./dataset/negative"
  hard_negative_dir: "./dataset/hard_negative"
  background_dir: "./dataset/background"
  rir_dir: "./dataset/rirs"
  processed_dir: "./dataset/processed"
  checkpoint_dir: "./models/checkpoints"
  export_dir: "./models/exported"

# ─────────────────────────────────────────────────────────────────
# TRAINING PARAMETERS
# ─────────────────────────────────────────────────────────────────
training:
  # Maximum steps for best quality
  training_steps: [50000, 20000]
  learning_rates: [0.001, 0.0001]
  batch_size: 128
  eval_step_interval: 500
  steps_per_epoch: 1000  # Approximate steps per epoch for mining calculations

  # Class weights - higher negative weight for fewer false accepts
  positive_class_weight: [1.0, 1.0]
  negative_class_weight: [25.0, 25.0]
  hard_negative_class_weight: [50.0, 50.0]

  # SpecAugment disabled (using full audio augmentation)
  time_mask_max_size: [0, 0]
  time_mask_count: [0, 0]
  freq_mask_max_size: [0, 0]
  freq_mask_count: [0, 0]

  # Checkpoint selection - stricter target for max quality
  minimization_metric: "ambient_false_positives_per_hour"
  target_minimization: 0.2
  maximization_metric: "average_viable_recall"
  # Hours of negative/background audio for FAH calculation
  ambient_duration_hours: 10.0

# ─────────────────────────────────────────────────────────────────
# MIXEDNET ARCHITECTURE
# ─────────────────────────────────────────────────────────────────
model:
  architecture: "mixednet"

  # okay_nabu architecture (official ESPHome MWW)
  first_conv_filters: 32
  first_conv_kernel_size: 5
  stride: 3
  pointwise_filters: "64,64,64,64"
  mixconv_kernel_sizes: "[5],[7,11],[9,15],[23]"
  repeat_in_block: "1,1,1,1"
  residual_connection: "0,0,0,0"

  # Common settings
  dropout_rate: 0.2
  l2_regularization: 0.0001

# ─────────────────────────────────────────────────────────────────
# AUGMENTATION (Full + extra for max quality)
# ─────────────────────────────────────────────────────────────────
augmentation:
  # Time-domain augmentations - higher probabilities
  SevenBandParametricEQ: 0.15
  TanhDistortion: 0.15
  PitchShift: 0.15
  BandStopFilter: 0.15
  AddColorNoise: 0.15
  AddBackgroundNoise: 0.8
  Gain: 1.0
  RIR: 0.6

  # Additional augmentations for max quality
  AddBackgroundNoiseFromFile: 0.3
  ApplyImpulseResponse: 0.4

  # Noise mixing parameters - wider range
  background_min_snr_db: -10
  background_max_snr_db: 15
  min_jitter_s: 0.19
  max_jitter_s: 0.21

  # Background sources - use your own dataset paths
  impulse_paths: ["./dataset/rirs"]
  background_paths: ["./dataset/background"]
  augmentation_duration_s: 3.2

# ─────────────────────────────────────────────────────────────────
# PERFORMANCE CONFIGURATION (Maximum resources)
# ─────────────────────────────────────────────────────────────────
performance:
  # GPU mandatory for max quality
  gpu_only: true
  mixed_precision: true

  # Maximum CPU resources
  num_workers: 16
  num_threads_per_worker: 2
  prefetch_factor: 8
  pin_memory: true
  max_memory_gb: 60

  # Maximum parallelism
  inter_op_parallelism: 16
  intra_op_parallelism: 16

  # Profiling enabled with detailed output
  enable_profiling: false
  profile_every_n_steps: 100
  profile_output_dir: "./profiles"

  # TensorBoard enabled with full metrics
  tensorboard_enabled: true
  tensorboard_log_dir: "./logs"

# ─────────────────────────────────────────────────────────────────
# SPEAKER CLUSTERING (Enabled with strict settings)
# ─────────────────────────────────────────────────────────────────
speaker_clustering:
  enabled: true
  method: "agglomerative"
  embedding_model: "speechbrain/ecapa-tdnn-voxceleb"
  similarity_threshold: 0.75
  leakage_audit_enabled: true

# ─────────────────────────────────────────────────────────────────
# HARD NEGATIVE MINING (Enabled with aggressive settings)
# ─────────────────────────────────────────────────────────────────
hard_negative_mining:
  enabled: true
  fp_threshold: 0.75
  max_samples: 10000
  mining_interval_epochs: 3

# ─────────────────────────────────────────────────────────────────
# EXPORT SETTINGS
# ─────────────────────────────────────────────────────────────────
export:
  wake_word: "Hey Katya"
  author: "Sarpel GURAY"
  website: "https://github.com/sarpel/microwakeword-training-platform"
  trained_languages: ["en"]

  quantize: true
  inference_input_type: "int8"
  inference_output_type: "uint8"

  # Wake word detection threshold (high-confidence production-safe threshold)
  # Validated optimal cutoff from model validation
  probability_cutoff: 0.97
  sliding_window_size: 5
  tensor_arena_size: 30000
  minimum_esphome_version: "2024.7.0"
